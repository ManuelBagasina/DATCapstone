{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuelBagasina/DATCapstone/blob/ML-Manuel/TFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "1vdYkOT0mC3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b ML-Manuel https://github.com/ManuelBagasina/DATCapstone.git\n",
        "%cd DATCapstone/data"
      ],
      "metadata": {
        "id": "Ewai5vAJmiDT",
        "outputId": "f24f0f4c-835e-4d0d-e122-0e69606217e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATCapstone'...\n",
            "remote: Enumerating objects: 706, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 706 (delta 116), reused 25 (delta 25), pack-reused 517 (from 3)\u001b[K\n",
            "Receiving objects: 100% (706/706), 68.60 MiB | 24.01 MiB/s, done.\n",
            "Resolving deltas: 100% (369/369), done.\n",
            "/content/DATCapstone/data/DATCapstone/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install pytorch-forecasting"
      ],
      "metadata": {
        "id": "7-DXlkU5mkTT",
        "outputId": "040542a8-b5a5-43d3-e0cc-8f8edd0214b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.0.2)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.5.1)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.14.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.6.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2025.3.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.14.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.7.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.13.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.19.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "lUgloDa6mI0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import torch\n",
        "import lightning.pytorch as pl\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import MAE, RMSE, SMAPE\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from zipfile import ZipFile\n",
        "from pytorch_forecasting.data.encoders import NaNLabelEncoder"
      ],
      "metadata": {
        "id": "AQuF70IEml4h"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and load the dataset\n",
        "with ZipFile('_data.csv.zip', 'r') as z:\n",
        "    with z.open('data.csv') as f:  # Ignore macOS metadata files\n",
        "        df = pd.read_csv(f, index_col=0)"
      ],
      "metadata": {
        "id": "Ut93Qa4kmnZb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ],
      "metadata": {
        "id": "JmLcP5JCmneJ",
        "outputId": "f559b2b2-cb6e-4490-c2f7-223f6576459e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n",
            "Using CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "rkwAzhR4mKhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic info about the dataset\n",
        "print(f\"Original dataframe shape: {df.shape}\")\n",
        "\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nUnique tickers:\")\n",
        "print(df['Ticker'].unique())\n",
        "print(f\"Number of unique tickers: {df['Ticker'].nunique()}\")\n",
        "\n",
        "# Convert date to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "3CahXmDimrRV",
        "outputId": "8085a8f6-1555-4f2d-9312-112b23ec218d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe shape: (8103, 817)\n",
            "\n",
            "First few rows:\n",
            "         Date       Open       High        Low      Close    Volume  \\\n",
            "0  2021-06-01  75.393341  75.630189  74.351213  75.383865  10485300   \n",
            "1  2021-06-02  75.507015  76.672309  75.327016  76.047028  12249300   \n",
            "2  2021-06-03  75.601763  77.174428  75.459653  76.823891  12038700   \n",
            "3  2021-06-04  77.136525  79.542898  77.089160  78.529190  14502900   \n",
            "4  2021-06-07  78.576573  79.817653  78.491304  79.523964  10445600   \n",
            "\n",
            "   Dividends  Stock Splits  GDP (Billions USD)  Unemployment Rate (%)  ...  \\\n",
            "0        0.0           0.0           23368.861                    5.9  ...   \n",
            "1        0.0           0.0           23368.861                    5.9  ...   \n",
            "2        0.0           0.0           23368.861                    5.9  ...   \n",
            "3        0.0           0.0           23368.861                    5.9  ...   \n",
            "4        0.0           0.0           23368.861                    5.9  ...   \n",
            "\n",
            "   emb_763  emb_764  emb_765  emb_766  emb_767  Target_1day  Target_1week  \\\n",
            "0      NaN      NaN      NaN      NaN      NaN     0.663162      4.774864   \n",
            "1      NaN      NaN      NaN      NaN      NaN     0.776863      4.026428   \n",
            "2      NaN      NaN      NaN      NaN      NaN     1.705299      1.146362   \n",
            "3      NaN      NaN      NaN      NaN      NaN     0.994774      0.009506   \n",
            "4      NaN      NaN      NaN      NaN      NaN     0.634766     -1.250549   \n",
            "\n",
            "   Target_1month  Target_1year  Ticker  \n",
            "0      -1.392677     -6.483879    ORCL  \n",
            "1      -2.302147     -6.070183    ORCL  \n",
            "2      -1.468452     -7.673927    ORCL  \n",
            "3      -1.013695     -9.686905    ORCL  \n",
            "4      -0.814743     -9.200996    ORCL  \n",
            "\n",
            "[5 rows x 817 columns]\n",
            "\n",
            "Unique tickers:\n",
            "['ORCL' 'MSFT' 'AAPL' 'AVGO' 'AMD' 'AMZN' 'GOOGL' 'META' 'TSLA' 'NVDA']\n",
            "Number of unique tickers: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "MW4N7e44mLyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove lag features since TFT will handle time dependencies\n",
        "lag_columns = [col for col in df.columns if '_lag' in col]\n",
        "print(f\"\\nRemoving {len(lag_columns)} lag columns from the dataset\")\n",
        "df_no_lag = df.drop(columns=lag_columns)\n",
        "\n",
        "# Handle embedding columns - Either keep them or use PCA to reduce dimensionality\n",
        "# Identify embedding columns\n",
        "emb_columns = [col for col in df_no_lag.columns if col.startswith('emb_')]\n",
        "print(f\"\\nFound {len(emb_columns)} embedding columns\")\n",
        "\n",
        "# Option 1: Remove embedding columns since they might be too many for TFT\n",
        "df_no_emb = df_no_lag.drop(columns=emb_columns)\n",
        "\n",
        "# We'll work with the version without embeddings for simplicity\n",
        "df_processed = df_no_emb"
      ],
      "metadata": {
        "id": "2BsyckKqmtQc",
        "outputId": "206c01c7-323c-4963-f115-b9a614b0b0b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Removing 0 lag columns from the dataset\n",
            "\n",
            "Found 768 embedding columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select target and features for the model\n",
        "target = 'Close'  # Or could be 'Close' , 'Target_1day', 'Target_1week', 'Target_1month', 'Target_1year'\n",
        "\n",
        "# Select relevant features for prediction\n",
        "# Exclude Date, target variables, and other non-predictive columns\n",
        "exclude_columns = ['Date'] + [col for col in df_processed.columns if col.startswith('Target_')]\n",
        "if target not in exclude_columns:\n",
        "    exclude_columns.append(target)\n",
        "features = [col for col in df_processed.columns if col not in exclude_columns]\n",
        "print(f\"\\nUsing {len(features)} features for prediction\")"
      ],
      "metadata": {
        "id": "O5Q3MzBSmuNv",
        "outputId": "93ae0119-f2ed-4b33-df9a-b639ba6f88f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using 43 features for prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time index for TFT\n",
        "df_processed['time_idx'] = df_processed.groupby('Ticker')['Date'].rank(method='dense').astype(int) - 1\n",
        "\n",
        "# Verify time_idx is properly set for each ticker\n",
        "for ticker in df_processed['Ticker'].unique():\n",
        "    ticker_data = df_processed[df_processed['Ticker'] == ticker]\n",
        "    print(f\"{ticker}: time_idx from {ticker_data['time_idx'].min()} to {ticker_data['time_idx'].max()}\")\n",
        "\n",
        "# Set parameters for prediction\n",
        "# If predicting Target_1day, max_prediction_length=1\n",
        "# If predicting Target_1week, max_prediction_length=5 (assuming 5 trading days)\n",
        "# If predicting Target_1month, max_prediction_length=20\n",
        "max_prediction_length = 1  # Adjust based on your prediction horizon\n",
        "max_encoder_length = 30    # Use 30 days of history for prediction"
      ],
      "metadata": {
        "id": "zK2DYAlFmuTO",
        "outputId": "22ef11fb-caee-4f85-ac00-afca9ec5202e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORCL: time_idx from 0 to 922\n",
            "MSFT: time_idx from 0 to 901\n",
            "AAPL: time_idx from 0 to 837\n",
            "AVGO: time_idx from 0 to 815\n",
            "AMD: time_idx from 0 to 773\n",
            "AMZN: time_idx from 0 to 773\n",
            "GOOGL: time_idx from 0 to 773\n",
            "META: time_idx from 0 to 773\n",
            "TSLA: time_idx from 0 to 773\n",
            "NVDA: time_idx from 0 to 753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup"
      ],
      "metadata": {
        "id": "3x5Td_OvmRSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a training dataset - Use the last 20% of the data for testing\n",
        "val_cutoff = df_processed['time_idx'].max() - max_prediction_length\n",
        "cutoffs = {}\n",
        "for ticker in df_processed['Ticker'].unique():\n",
        "    ticker_data = df_processed[df_processed['Ticker'] == ticker]\n",
        "    cutoffs[ticker] = ticker_data['time_idx'].max() * 0.8\n",
        "\n",
        "df_processed['is_train'] = True\n",
        "for ticker, cutoff in cutoffs.items():\n",
        "    df_processed.loc[(df_processed['Ticker'] == ticker) &\n",
        "                    (df_processed['time_idx'] > cutoff), 'is_train'] = False"
      ],
      "metadata": {
        "id": "wxXYx1YkmzBp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which columns have missing values\n",
        "missing_columns = df_processed.isna().sum()\n",
        "print(\"\\nColumns with missing values:\")\n",
        "print(missing_columns[missing_columns > 0].sort_values(ascending=False))\n",
        "\n",
        "# Check for infinite values\n",
        "df_processed = df_processed.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Handle missing values in Inventory specifically (since that's causing the error)\n",
        "if 'Inventory' in df_processed.columns:\n",
        "    # For each ticker, fill missing Inventory values with median (or 0 if median is NaN)\n",
        "    for ticker in df_processed['Ticker'].unique():\n",
        "        ticker_mask = df_processed['Ticker'] == ticker\n",
        "        ticker_inventory_median = df_processed.loc[ticker_mask, 'Inventory'].median()\n",
        "        if pd.isna(ticker_inventory_median):\n",
        "            ticker_inventory_median = 0\n",
        "        df_processed.loc[ticker_mask, 'Inventory'] = df_processed.loc[ticker_mask, 'Inventory'].fillna(ticker_inventory_median)"
      ],
      "metadata": {
        "id": "kn573usJm1Ex",
        "outputId": "110a11ec-b558-4e3c-d2e5-a5661f36f0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns with missing values:\n",
            "neutral                        5378\n",
            "negative                       5378\n",
            "vote                           5378\n",
            "positive                       5378\n",
            "Target_1year                   2500\n",
            "Inventory                      1697\n",
            "Repurchase Of Capital Stock     774\n",
            "Long Term Debt                  252\n",
            "Target_1month                   200\n",
            "Target_1week                     50\n",
            "Target_1day                      10\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all features for missing values and fill appropriately\n",
        "for feature in features:\n",
        "    if df_processed[feature].isna().sum() > 0:\n",
        "        print(f\"Filling missing values in {feature}\")\n",
        "        # Fill by ticker\n",
        "        for ticker in df_processed['Ticker'].unique():\n",
        "            ticker_mask = df_processed['Ticker'] == ticker\n",
        "            feature_median = df_processed.loc[ticker_mask, feature].median()\n",
        "            if pd.isna(feature_median):  # If median is NaN (all values are NaN)\n",
        "                feature_median = 0\n",
        "            df_processed.loc[ticker_mask, feature] = df_processed.loc[ticker_mask, feature].fillna(feature_median)\n",
        "\n",
        "# Verify all missing values are fixed\n",
        "remaining_missing = df_processed[features].isna().sum()\n",
        "if remaining_missing.sum() > 0:\n",
        "    print(\"Warning: There are still missing values:\")\n",
        "    print(remaining_missing[remaining_missing > 0])\n",
        "else:\n",
        "    print(\"All missing values have been handled.\")"
      ],
      "metadata": {
        "id": "OqscoTt6m5rR",
        "outputId": "72b93e56-f229-4776-8b5d-25ebeb006c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All missing values have been handled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TimeSeriesDataSets"
      ],
      "metadata": {
        "id": "Ke28zgd1mSFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduced feature set for simplicity\n",
        "reduced_features = features[:20]  # Use only the first 20 features to simplify\n",
        "\n",
        "# Create training dataset\n",
        "training = TimeSeriesDataSet(\n",
        "    data=df_processed[df_processed['is_train']],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=target,\n",
        "    group_ids=[\"Ticker\"],\n",
        "    min_encoder_length=15,  # Reduced from 30\n",
        "    max_encoder_length=15,  # Reduced from 30\n",
        "    min_prediction_length=1,\n",
        "    max_prediction_length=1,\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    static_reals=[],\n",
        "    time_varying_known_categoricals=[],\n",
        "    time_varying_known_reals=[\"time_idx\"],\n",
        "    time_varying_unknown_categoricals=[],\n",
        "    time_varying_unknown_reals=reduced_features,  # Use reduced feature set\n",
        "    target_normalizer=GroupNormalizer(\n",
        "        groups=[\"Ticker\"], transformation=\"softplus\"\n",
        "    ),\n",
        "    categorical_encoders={\n",
        "        \"Ticker\": NaNLabelEncoder(add_nan=True)\n",
        "    },\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        ")"
      ],
      "metadata": {
        "id": "aLM2UhLtm3lN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify there are no lag features in the data\n",
        "print(\"Lag feature verification:\")\n",
        "lag_features = [col for col in df.columns if '_lag' in col]\n",
        "print(f\"Number of lag features in original dataframe: {len(lag_features)}\")\n",
        "if len(lag_features) == 0:\n",
        "    print(\"No lag features found in dataframe. These will be handled by TFT automatically.\")\n",
        "else:\n",
        "    print(\"Lag features found in dataframe. Consider removing them to let TFT handle temporal dependencies.\")\n",
        "    print(f\"First few lag features: {lag_features[:5]}\")"
      ],
      "metadata": {
        "id": "eUx6Zuw7m8QG",
        "outputId": "0d1a33ca-6121-4e03-fc49-cc036d77b6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lag feature verification:\n",
            "Number of lag features in original dataframe: 0\n",
            "No lag features found in dataframe. These will be handled by TFT automatically.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check ticker sequence organization\n",
        "ticker_counts = df_processed.groupby('Ticker').size()\n",
        "print(\"\\nRows per ticker:\")\n",
        "print(ticker_counts)"
      ],
      "metadata": {
        "id": "zgl3DdIzm8Ws",
        "outputId": "3737743c-eae9-447d-d80f-0462e43f5bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rows per ticker:\n",
            "Ticker\n",
            "AAPL     838\n",
            "AMD      774\n",
            "AMZN     774\n",
            "AVGO     816\n",
            "GOOGL    774\n",
            "META     774\n",
            "MSFT     902\n",
            "NVDA     754\n",
            "ORCL     923\n",
            "TSLA     774\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are enough data points per ticker for the encoder length\n",
        "min_required = max_encoder_length + max_prediction_length\n",
        "print(f\"\\nTickers with insufficient data (<{min_required} points):\")\n",
        "print(ticker_counts[ticker_counts < min_required])"
      ],
      "metadata": {
        "id": "EckxLjbRm8Z1",
        "outputId": "8e4401e4-8127-4fd9-c138-7276d54fd58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tickers with insufficient data (<31 points):\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show time index consistency by ticker\n",
        "print(\"\\nTime index range by ticker:\")\n",
        "for ticker in df_processed['Ticker'].unique():\n",
        "    ticker_data = df_processed[df_processed['Ticker'] == ticker]\n",
        "    print(f\"{ticker}: {ticker_data['time_idx'].min()} to {ticker_data['time_idx'].max()} ({len(ticker_data)} rows)\")"
      ],
      "metadata": {
        "id": "LUQhP-X7m8dl",
        "outputId": "0e46af27-ccc5-4bcc-f6db-26dbb5f888f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time index range by ticker:\n",
            "ORCL: 0 to 922 (923 rows)\n",
            "MSFT: 0 to 901 (902 rows)\n",
            "AAPL: 0 to 837 (838 rows)\n",
            "AVGO: 0 to 815 (816 rows)\n",
            "AMD: 0 to 773 (774 rows)\n",
            "AMZN: 0 to 773 (774 rows)\n",
            "GOOGL: 0 to 773 (774 rows)\n",
            "META: 0 to 773 (774 rows)\n",
            "TSLA: 0 to 773 (774 rows)\n",
            "NVDA: 0 to 753 (754 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle NaN values in target columns\n",
        "print(f\"Number of rows with NA in {target}: {df_processed[target].isna().sum()}\")\n",
        "df_processed[target] = df_processed[target].fillna(0)  # Fill with 0 or another appropriate value\n",
        "print(f\"NAs remaining in {target}: {df_processed[target].isna().sum()}\")"
      ],
      "metadata": {
        "id": "tU7WU9F_m8hH",
        "outputId": "8b7aa191-ba17-481d-babb-f9f551337957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with NA in Close: 0\n",
            "NAs remaining in Close: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create validation dataset and dataloaders\n",
        "validation = TimeSeriesDataSet.from_dataset(\n",
        "    training, df_processed[~df_processed['is_train']], predict=True, stop_randomization=True\n",
        ")"
      ],
      "metadata": {
        "id": "H3iTIeAtm8jz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders for model training\n",
        "batch_size = 32  # Adjust based on  GPU memory\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0, shuffle=False)\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0, shuffle=False)"
      ],
      "metadata": {
        "id": "mZYEMh5-m8pw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "zNudr8NLmVdb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kva-aXg9nHea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation and Prediction"
      ],
      "metadata": {
        "id": "r9x9I8ylmWQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "Y5p-nNO4mX65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "tYdrfvF0mamT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model"
      ],
      "metadata": {
        "id": "K3aq07d8mb8t"
      }
    }
  ]
}