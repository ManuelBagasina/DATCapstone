{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuelBagasina/DATCapstone/blob/ML-Manuel/RF%26LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreProcessing"
      ],
      "metadata": {
        "id": "n_anRoz5HmFo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MoMkqe4pjPeN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b ML-Manuel https://github.com/ManuelBagasina/DATCapstone.git\n",
        "%cd DATCapstone/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gZtLPLUq2Iy",
        "outputId": "df9f8cea-0373-4d3f-b535-0b912c7b8806"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATCapstone'...\n",
            "remote: Enumerating objects: 505, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 505 (delta 76), reused 27 (delta 25), pack-reused 385 (from 1)\u001b[K\n",
            "Receiving objects: 100% (505/505), 61.59 MiB | 6.88 MiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n",
            "Updating files: 100% (24/24), done.\n",
            "/content/DATCapstone/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "\n",
        "# Explicitly extract data.csv from ZIP\n",
        "with ZipFile('_data.csv.zip', 'r') as z:\n",
        "    with z.open('data.csv') as f:  # Ignore macOS metadata files\n",
        "        df = pd.read_csv(f, index_col=0)\n",
        "\n",
        "# Convert date and sort\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df = df.sort_values(by=['Ticker', 'Date'])\n"
      ],
      "metadata": {
        "id": "xPTgGyN8q5lV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p-hY9x9NjPeQ",
        "outputId": "4d8d5409-4194-4afb-e3dc-e770ef10065a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date        Open        High         Low       Close    Volume  \\\n",
              "149  2021-09-30  140.983670  141.690258  138.648004  138.863907  89056700   \n",
              "152  2021-10-01  139.256450  140.257452  136.518433  139.992477  94639600   \n",
              "155  2021-10-04  139.119037  139.560665  135.694064  136.547852  98322000   \n",
              "158  2021-10-05  136.891371  139.590139  136.763788  138.481186  80861100   \n",
              "161  2021-10-06  136.871718  139.501783  135.792205  139.354584  83221100   \n",
              "...         ...         ...         ...         ...         ...       ...   \n",
              "8062 2025-01-27  394.799988  406.690002  389.000000  397.149994  58125500   \n",
              "8072 2025-01-28  396.910004  400.589996  386.500000  398.089996  48910700   \n",
              "8082 2025-01-29  395.209991  398.589996  384.480011  389.100006  68033600   \n",
              "8092 2025-01-30  410.779999  412.500000  384.410004  400.279999  98092900   \n",
              "8102 2025-01-31  401.529999  419.989990  401.339996  404.600006  83568200   \n",
              "\n",
              "      Dividends  Stock Splits  GDP (Billions USD)  Unemployment Rate (%)  ...  \\\n",
              "149         0.0           0.0           23921.991                    4.7  ...   \n",
              "152         0.0           0.0           24777.038                    4.5  ...   \n",
              "155         0.0           0.0           24777.038                    4.5  ...   \n",
              "158         0.0           0.0           24777.038                    4.5  ...   \n",
              "161         0.0           0.0           24777.038                    4.5  ...   \n",
              "...         ...           ...                 ...                    ...  ...   \n",
              "8062        0.0           0.0           29723.864                    4.0  ...   \n",
              "8072        0.0           0.0           29723.864                    4.0  ...   \n",
              "8082        0.0           0.0           29723.864                    4.0  ...   \n",
              "8092        0.0           0.0           29723.864                    4.0  ...   \n",
              "8102        0.0           0.0           29723.864                    4.0  ...   \n",
              "\n",
              "       emb_763   emb_764   emb_765   emb_766   emb_767  Target_1day  \\\n",
              "149        NaN       NaN       NaN       NaN       NaN     1.128571   \n",
              "152        NaN       NaN       NaN       NaN       NaN    -3.444626   \n",
              "155        NaN       NaN       NaN       NaN       NaN     1.933334   \n",
              "158        NaN       NaN       NaN       NaN       NaN     0.873398   \n",
              "161        NaN       NaN       NaN       NaN       NaN     1.265976   \n",
              "...        ...       ...       ...       ...       ...          ...   \n",
              "8062  1.174326 -0.262426  0.298183  0.182200  0.388200     0.940002   \n",
              "8072  0.084330 -0.354550 -0.611864 -0.449780  0.584349    -8.989990   \n",
              "8082  0.827862 -0.620100 -0.024186 -0.439615  0.781107    11.179993   \n",
              "8092  1.383147 -0.616897 -0.145329 -0.418483  0.636253     4.320007   \n",
              "8102  0.658588 -0.312093 -0.158066 -0.211410  0.834208          NaN   \n",
              "\n",
              "      Target_1week  Target_1month  Target_1year  Ticker  \n",
              "149       1.756653      10.863785      9.008606    AAPL  \n",
              "152       0.245331       7.016815      0.616699    AAPL  \n",
              "155       3.601639       9.637100     -0.162491    AAPL  \n",
              "158       0.392532       8.744034      2.098389    AAPL  \n",
              "161      -1.069687       9.313263      4.827057    AAPL  \n",
              "...            ...            ...           ...     ...  \n",
              "8062           NaN            NaN           NaN    TSLA  \n",
              "8072           NaN            NaN           NaN    TSLA  \n",
              "8082           NaN            NaN           NaN    TSLA  \n",
              "8092           NaN            NaN           NaN    TSLA  \n",
              "8102           NaN            NaN           NaN    TSLA  \n",
              "\n",
              "[8103 rows x 817 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-501c30d5-9353-45e2-a21e-34fd7c7c8544\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>GDP (Billions USD)</th>\n",
              "      <th>Unemployment Rate (%)</th>\n",
              "      <th>...</th>\n",
              "      <th>emb_763</th>\n",
              "      <th>emb_764</th>\n",
              "      <th>emb_765</th>\n",
              "      <th>emb_766</th>\n",
              "      <th>emb_767</th>\n",
              "      <th>Target_1day</th>\n",
              "      <th>Target_1week</th>\n",
              "      <th>Target_1month</th>\n",
              "      <th>Target_1year</th>\n",
              "      <th>Ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>140.983670</td>\n",
              "      <td>141.690258</td>\n",
              "      <td>138.648004</td>\n",
              "      <td>138.863907</td>\n",
              "      <td>89056700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23921.991</td>\n",
              "      <td>4.7</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.128571</td>\n",
              "      <td>1.756653</td>\n",
              "      <td>10.863785</td>\n",
              "      <td>9.008606</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>139.256450</td>\n",
              "      <td>140.257452</td>\n",
              "      <td>136.518433</td>\n",
              "      <td>139.992477</td>\n",
              "      <td>94639600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3.444626</td>\n",
              "      <td>0.245331</td>\n",
              "      <td>7.016815</td>\n",
              "      <td>0.616699</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>139.119037</td>\n",
              "      <td>139.560665</td>\n",
              "      <td>135.694064</td>\n",
              "      <td>136.547852</td>\n",
              "      <td>98322000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.933334</td>\n",
              "      <td>3.601639</td>\n",
              "      <td>9.637100</td>\n",
              "      <td>-0.162491</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>2021-10-05</td>\n",
              "      <td>136.891371</td>\n",
              "      <td>139.590139</td>\n",
              "      <td>136.763788</td>\n",
              "      <td>138.481186</td>\n",
              "      <td>80861100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.873398</td>\n",
              "      <td>0.392532</td>\n",
              "      <td>8.744034</td>\n",
              "      <td>2.098389</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2021-10-06</td>\n",
              "      <td>136.871718</td>\n",
              "      <td>139.501783</td>\n",
              "      <td>135.792205</td>\n",
              "      <td>139.354584</td>\n",
              "      <td>83221100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.265976</td>\n",
              "      <td>-1.069687</td>\n",
              "      <td>9.313263</td>\n",
              "      <td>4.827057</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8062</th>\n",
              "      <td>2025-01-27</td>\n",
              "      <td>394.799988</td>\n",
              "      <td>406.690002</td>\n",
              "      <td>389.000000</td>\n",
              "      <td>397.149994</td>\n",
              "      <td>58125500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29723.864</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.174326</td>\n",
              "      <td>-0.262426</td>\n",
              "      <td>0.298183</td>\n",
              "      <td>0.182200</td>\n",
              "      <td>0.388200</td>\n",
              "      <td>0.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TSLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8072</th>\n",
              "      <td>2025-01-28</td>\n",
              "      <td>396.910004</td>\n",
              "      <td>400.589996</td>\n",
              "      <td>386.500000</td>\n",
              "      <td>398.089996</td>\n",
              "      <td>48910700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29723.864</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084330</td>\n",
              "      <td>-0.354550</td>\n",
              "      <td>-0.611864</td>\n",
              "      <td>-0.449780</td>\n",
              "      <td>0.584349</td>\n",
              "      <td>-8.989990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TSLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8082</th>\n",
              "      <td>2025-01-29</td>\n",
              "      <td>395.209991</td>\n",
              "      <td>398.589996</td>\n",
              "      <td>384.480011</td>\n",
              "      <td>389.100006</td>\n",
              "      <td>68033600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29723.864</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827862</td>\n",
              "      <td>-0.620100</td>\n",
              "      <td>-0.024186</td>\n",
              "      <td>-0.439615</td>\n",
              "      <td>0.781107</td>\n",
              "      <td>11.179993</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TSLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8092</th>\n",
              "      <td>2025-01-30</td>\n",
              "      <td>410.779999</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>384.410004</td>\n",
              "      <td>400.279999</td>\n",
              "      <td>98092900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29723.864</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.383147</td>\n",
              "      <td>-0.616897</td>\n",
              "      <td>-0.145329</td>\n",
              "      <td>-0.418483</td>\n",
              "      <td>0.636253</td>\n",
              "      <td>4.320007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TSLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8102</th>\n",
              "      <td>2025-01-31</td>\n",
              "      <td>401.529999</td>\n",
              "      <td>419.989990</td>\n",
              "      <td>401.339996</td>\n",
              "      <td>404.600006</td>\n",
              "      <td>83568200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29723.864</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.658588</td>\n",
              "      <td>-0.312093</td>\n",
              "      <td>-0.158066</td>\n",
              "      <td>-0.211410</td>\n",
              "      <td>0.834208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TSLA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8103 rows Ã— 817 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-501c30d5-9353-45e2-a21e-34fd7c7c8544')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-501c30d5-9353-45e2-a21e-34fd7c7c8544 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-501c30d5-9353-45e2-a21e-34fd7c7c8544');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69417d69-3ac0-401b-b502-9d283b266ac3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69417d69-3ac0-401b-b502-9d283b266ac3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69417d69-3ac0-401b-b502-9d283b266ac3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b92f23da-a73f-44e2-85be-d1b192e762af\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b92f23da-a73f-44e2-85be-d1b192e762af button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wlMGyliRjPeR"
      },
      "outputs": [],
      "source": [
        "#Read Data\n",
        "# df = pd.read_csv('/Users/wonminkim/Projects/DATCapstone/data2/data.csv', index_col=0)\n",
        "# Correct path for ZIP file\n",
        "zip_path = '/content/DATCapstone/data/_data.csv.zip'\n",
        "\n",
        "# Extract specific file from ZIP\n",
        "with ZipFile(zip_path, 'r') as z:\n",
        "    with z.open('data.csv') as f:  # Explicitly specify the file to extract\n",
        "        df = pd.read_csv(f, index_col=0)\n",
        "\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "#Forward fill -> micro, macro, stock / fill na -> sentiment\n",
        "df[df.columns[1:40]] = df.groupby('Ticker')[df.columns[1:40]].ffill()\n",
        "df[df.columns[40:-5]] = df[df.columns[40:-5]].fillna(0)\n",
        "\n",
        "df = df.dropna(subset=df.columns[0:-5])\n",
        "\n",
        "# Sorting\n",
        "df = df.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
        "\n",
        "# Lag feature (Exclude embedding columns)\n",
        "lag_cols = df.columns[1:44]\n",
        "lags = [1, 3, 5, 7, 14, 30]\n",
        "lag_features = []\n",
        "\n",
        "for col in lag_cols:\n",
        "    for lag in lags:\n",
        "        lagged = df.groupby('Ticker')[col].shift(lag)\n",
        "        lag_features.append(lagged.rename(f'{col}_lag{lag}'))\n",
        "\n",
        "lag_df = pd.concat(lag_features, axis=1)\n",
        "\n",
        "df = pd.concat([df.reset_index(drop=True), lag_df.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "source": [
        "!git clone -b ML-Manuel https://github.com/ManuelBagasina/DATCapstone.git\n",
        "%cd DATCapstone/data"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fAczgpf6ETBG",
        "outputId": "9e240629-8450-42f7-b509-4a60ef0bce3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATCapstone'...\n",
            "remote: Enumerating objects: 505, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 505 (delta 76), reused 27 (delta 25), pack-reused 385 (from 1)\u001b[K\n",
            "Receiving objects: 100% (505/505), 61.59 MiB | 9.27 MiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n",
            "/content/DATCapstone/data/DATCapstone/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# Correct path for article CSVs in Google Colab\n",
        "csv_files = glob.glob('/content/DATCapstone/data/*articles*.csv')\n",
        "print(\"Found files:\", csv_files)  # Debugging\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLm2BNBPrrzC",
        "outputId": "35f9c746-9771-4347-8b7d-55274bc39716"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: ['/content/DATCapstone/data/AMZN_articles..csv', '/content/DATCapstone/data/AAPL_articles.csv', '/content/DATCapstone/data/NVDA_articles..csv', '/content/DATCapstone/data/AVGO_articles..csv', '/content/DATCapstone/data/ADBE_articles.csv', '/content/DATCapstone/data/TSLA_articles..csv', '/content/DATCapstone/data/GOOGL_articles..csv', '/content/DATCapstone/data/MSFT_articles..csv', '/content/DATCapstone/data/META_articles..csv', '/content/DATCapstone/data/NFLX_articles..csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/DATCapstone/data/*articles*.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snh0zr9_ruQE",
        "outputId": "c6004a68-a229-4ed5-9d09-4a61d3119bc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DATCapstone/data/AAPL_articles.csv\n",
            "/content/DATCapstone/data/ADBE_articles.csv\n",
            "/content/DATCapstone/data/AMZN_articles..csv\n",
            "/content/DATCapstone/data/AVGO_articles..csv\n",
            "/content/DATCapstone/data/GOOGL_articles..csv\n",
            "/content/DATCapstone/data/META_articles..csv\n",
            "/content/DATCapstone/data/MSFT_articles..csv\n",
            "/content/DATCapstone/data/NFLX_articles..csv\n",
            "/content/DATCapstone/data/NVDA_articles..csv\n",
            "/content/DATCapstone/data/TSLA_articles..csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not csv_files:\n",
        "    print(\"No article files found. Initializing empty columns.\")\n",
        "    df_articles = pd.DataFrame(columns=['Date', 'Ticker', 'Articles_Negative', 'Articles_Neutral', 'Articles_positive'])\n",
        "else:\n",
        "    # Your existing processing code\n",
        "    df_articles_list = []\n",
        "    for file in csv_files:\n",
        "        ticker = os.path.basename(file).split('_')[0]\n",
        "        df_articles = pd.read_csv(file)\n",
        "        df_articles['Ticker'] = ticker\n",
        "        df_articles_list.append(df_articles)\n",
        "\n",
        "    df_articles = pd.concat(df_articles_list, ignore_index=True)\n",
        "\n",
        "    # Preprocessing steps...\n",
        "# Articles dataframe preprocessing\n",
        "df_articles[\"Date\"] = pd.to_datetime(df_articles[\"time\"], errors='coerce', utc=True).dt.tz_convert(None).dt.date\n",
        "df_articles = df_articles[['Date', 'Ticker', 'sentiment']]\n",
        "sentiment_dummies = pd.get_dummies(df_articles['sentiment'])\n",
        "df_encoded = pd.concat([df_articles[['Date', 'Ticker']], sentiment_dummies], axis=1)\n",
        "df_articles = df_encoded.groupby(['Date', 'Ticker']).sum().reset_index()\n",
        "df_articles['Date'] = pd.to_datetime(df_articles['Date'])\n",
        "\n",
        "df_articles['articles_avg_sentiment'] = (df_articles['Negative'] * -1 + df_articles['Neutral'] * 0 + df_articles['Positive']) / (df_articles['Negative'] + df_articles['Neutral'] + df_articles['Positive'])\n",
        "df_articles.columns = ['Date', 'Ticker', 'Articles_Negative', 'Articles_Neutral', 'Articles_positive', 'Articles_avg_sentiment']\n",
        "df_articles\n",
        "\n",
        "df = pd.merge(df, df_articles, on=['Date', 'Ticker'], how = 'left')\n",
        "\n",
        "# Fill 0 except the target columns\n",
        "df[[col for col in df.columns if 'Target' not in col]] = df[[col for col in df.columns if 'Target' not in col]].fillna(0)"
      ],
      "metadata": {
        "id": "aA7mmyvQrxxN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sj5krYQfjPeS"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Read articles df\n",
        "csv_files = glob.glob(os.path.join(\"*_articles*.csv\")) # Updated to reflect file naming pattern\n",
        "\n",
        "df_articles_list = []\n",
        "\n",
        "for file in csv_files:\n",
        "    # get ticker from filename\n",
        "    ticker = os.path.basename(file).split('_')[0]\n",
        "    df_articles = pd.read_csv(file)\n",
        "    df_articles['Ticker'] = ticker\n",
        "    df_articles_list.append(df_articles)\n",
        "\n",
        "# concat articles dataframe\n",
        "df_articles = pd.concat(df_articles_list, ignore_index=True)\n",
        "\n",
        "# Articles dataframe preprocessing\n",
        "df_articles[\"Date\"] = pd.to_datetime(df_articles[\"time\"], errors='coerce', utc=True).dt.tz_convert(None).dt.date\n",
        "df_articles = df_articles[['Date', 'Ticker', 'sentiment']]\n",
        "sentiment_dummies = pd.get_dummies(df_articles['sentiment'])\n",
        "df_encoded = pd.concat([df_articles[['Date', 'Ticker']], sentiment_dummies], axis=1)\n",
        "df_articles = df_encoded.groupby(['Date', 'Ticker']).sum().reset_index()\n",
        "df_articles['Date'] = pd.to_datetime(df_articles['Date'])\n",
        "\n",
        "df_articles['articles_avg_sentiment'] = (df_articles['Negative'] * -1 + df_articles['Neutral'] * 0 + df_articles['Positive']) / (df_articles['Negative'] + df_articles['Neutral'] + df_articles['Positive'])\n",
        "df_articles.columns = ['Date', 'Ticker', 'Articles_Negative', 'Articles_Neutral', 'Articles_positive', 'Articles_avg_sentiment']\n",
        "df_articles\n",
        "\n",
        "df = pd.merge(df, df_articles, on=['Date', 'Ticker'], how = 'left')\n",
        "\n",
        "# Fill 0 except the target columns\n",
        "df[[col for col in df.columns if 'Target' not in col]] = df[[col for col in df.columns if 'Target' not in col]].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_articles.columns)"
      ],
      "metadata": {
        "id": "r1A8RAO5Y92p",
        "outputId": "0d5524df-6ac4-42f9-d837-05a07fa874f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Ticker', 'Articles_Negative', 'Articles_Neutral',\n",
            "       'Articles_positive', 'Articles_avg_sentiment'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Linear\n"
      ],
      "metadata": {
        "id": "nYJMmrulHrVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEGjy1lrjPeS",
        "outputId": "041b6d5e-328b-4917-f68e-29bd1311a6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date        Open        High         Low       Close    Volume  \\\n",
              "0 2021-09-30  140.983670  141.690258  138.648004  138.863907  89056700   \n",
              "1 2021-10-01  139.256450  140.257452  136.518433  139.992477  94639600   \n",
              "2 2021-10-04  139.119037  139.560665  135.694064  136.547852  98322000   \n",
              "3 2021-10-05  136.891371  139.590139  136.763788  138.481186  80861100   \n",
              "4 2021-10-06  136.871718  139.501783  135.792205  139.354584  83221100   \n",
              "\n",
              "   Dividends  Stock Splits  GDP (Billions USD)  Unemployment Rate (%)  ...  \\\n",
              "0        0.0           0.0           23921.991                    4.7  ...   \n",
              "1        0.0           0.0           24777.038                    4.5  ...   \n",
              "2        0.0           0.0           24777.038                    4.5  ...   \n",
              "3        0.0           0.0           24777.038                    4.5  ...   \n",
              "4        0.0           0.0           24777.038                    4.5  ...   \n",
              "\n",
              "   emb_pca_74  emb_pca_75  emb_pca_76  emb_pca_77  emb_pca_78  emb_pca_79  \\\n",
              "0   -0.000573   -0.000315   -0.000716   -0.000052    0.000158    0.000176   \n",
              "1   -0.000573   -0.000315   -0.000716   -0.000052    0.000158    0.000176   \n",
              "2   -0.000573   -0.000315   -0.000716   -0.000052    0.000158    0.000176   \n",
              "3   -0.000573   -0.000315   -0.000716   -0.000052    0.000158    0.000176   \n",
              "4   -0.000573   -0.000315   -0.000716   -0.000052    0.000158    0.000176   \n",
              "\n",
              "   emb_pca_80  emb_pca_81  emb_pca_82  emb_pca_83  \n",
              "0    0.000412   -0.000354   -0.000744    0.000022  \n",
              "1    0.000412   -0.000354   -0.000744    0.000022  \n",
              "2    0.000412   -0.000354   -0.000744    0.000022  \n",
              "3    0.000412   -0.000354   -0.000744    0.000022  \n",
              "4    0.000412   -0.000354   -0.000744    0.000022  \n",
              "\n",
              "[5 rows x 399 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64d61570-bc81-4b82-8d75-d1ec64ccc890\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>GDP (Billions USD)</th>\n",
              "      <th>Unemployment Rate (%)</th>\n",
              "      <th>...</th>\n",
              "      <th>emb_pca_74</th>\n",
              "      <th>emb_pca_75</th>\n",
              "      <th>emb_pca_76</th>\n",
              "      <th>emb_pca_77</th>\n",
              "      <th>emb_pca_78</th>\n",
              "      <th>emb_pca_79</th>\n",
              "      <th>emb_pca_80</th>\n",
              "      <th>emb_pca_81</th>\n",
              "      <th>emb_pca_82</th>\n",
              "      <th>emb_pca_83</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>140.983670</td>\n",
              "      <td>141.690258</td>\n",
              "      <td>138.648004</td>\n",
              "      <td>138.863907</td>\n",
              "      <td>89056700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23921.991</td>\n",
              "      <td>4.7</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>139.256450</td>\n",
              "      <td>140.257452</td>\n",
              "      <td>136.518433</td>\n",
              "      <td>139.992477</td>\n",
              "      <td>94639600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>139.119037</td>\n",
              "      <td>139.560665</td>\n",
              "      <td>135.694064</td>\n",
              "      <td>136.547852</td>\n",
              "      <td>98322000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-10-05</td>\n",
              "      <td>136.891371</td>\n",
              "      <td>139.590139</td>\n",
              "      <td>136.763788</td>\n",
              "      <td>138.481186</td>\n",
              "      <td>80861100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-10-06</td>\n",
              "      <td>136.871718</td>\n",
              "      <td>139.501783</td>\n",
              "      <td>135.792205</td>\n",
              "      <td>139.354584</td>\n",
              "      <td>83221100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24777.038</td>\n",
              "      <td>4.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000573</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>-0.000354</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 399 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64d61570-bc81-4b82-8d75-d1ec64ccc890')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64d61570-bc81-4b82-8d75-d1ec64ccc890 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64d61570-bc81-4b82-8d75-d1ec64ccc890');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ddd75e3-7c06-4c35-be1d-1511c02ab5ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ddd75e3-7c06-4c35-be1d-1511c02ab5ae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ddd75e3-7c06-4c35-be1d-1511c02ab5ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pca"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "emb_cols = [col for col in df.columns if col.startswith(\"emb_\")]\n",
        "X_emb = df[emb_cols]\n",
        "X_emb_pca = pca.fit_transform(X_emb)\n",
        "\n",
        "# PCA columns\n",
        "pca_columns = [f\"emb_pca_{i}\" for i in range(X_emb_pca.shape[1])]\n",
        "df_pca_part = pd.DataFrame(X_emb_pca, columns=pca_columns, index=df.index)\n",
        "df_non_pca = df.drop(columns=emb_cols)\n",
        "\n",
        "df_pca = pd.concat([df_non_pca.reset_index(drop=True), df_pca_part.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# ê²°ê³¼ í™•ì¸\n",
        "df_pca.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBW_5_aJjPeW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def random_forest(data, target):\n",
        "    df = data.copy()\n",
        "    remove_target_col = [col for col in df.columns if 'Target' in col]\n",
        "    remove_target_col.remove(target)\n",
        "\n",
        "    # Drop other Targets and NaNs\n",
        "    df = df.drop(columns=remove_target_col)\n",
        "    df = df.dropna(subset=[target])\n",
        "\n",
        "    # Date processing\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # One-hot encode Ticker\n",
        "    df = pd.get_dummies(df, columns=['Ticker'], drop_first=True)\n",
        "\n",
        "    # X, y\n",
        "    y = df[target]\n",
        "    X = df.drop(columns=['Date', target])\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Train/Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [None, 10, 20]\n",
        "    }\n",
        "\n",
        "    # GridSearchCV\n",
        "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42),\n",
        "                               param_grid,\n",
        "                               cv=3,\n",
        "                               scoring='neg_mean_squared_error',\n",
        "                               n_jobs=-1,\n",
        "                               verbose=1)\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(\"Best Parameters:\")\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "    # Prediction\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluation\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n Evaluation:\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"RÂ² Score: {r2:.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    test_index = np.arange(len(y_test))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(test_index, y_test.values, label='Actual', linewidth=2)\n",
        "    plt.plot(test_index, y_pred, label='Predicted', linewidth=2)\n",
        "    plt.title(f'{target}: Actual vs Predicted')\n",
        "    plt.xlabel('Test Sample Index')\n",
        "    plt.ylabel(target)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxIMkxQ2jPeX",
        "outputId": "91fdf6ea-8ee3-47d0-d2f0-df7ef765ca14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-923ac070161d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target_1day'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target_1week'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target_1month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target_1year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-371d369f5bfb>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m     45\u001b[0m                                verbose=1)\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "random_forest(df, 'Target_1day')\n",
        "random_forest(df, 'Target_1week')\n",
        "random_forest(df, 'Target_1month')\n",
        "random_forest(df, 'Target_1year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU1bFivHjPeY"
      },
      "outputs": [],
      "source": [
        "random_forest(df_pca, 'Target_1day')\n",
        "random_forest(df_pca, 'Target_1week')\n",
        "random_forest(df_pca, 'Target_1month')\n",
        "random_forest(df_pca, 'Target_1year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzaeoJ63jPeY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lightgbm as lgb\n",
        "\n",
        "def lightgbm_model(data, target):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Target setting\n",
        "    remove_target_col = [col for col in df.columns if 'Target' in col]\n",
        "    remove_target_col.remove(target)\n",
        "    df = df.drop(columns=remove_target_col)\n",
        "    df = df.dropna(subset=[target])\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Ticker encoding\n",
        "    df = pd.get_dummies(df, columns=['Ticker'], drop_first=True)\n",
        "\n",
        "    # X, y\n",
        "    y = df[target]\n",
        "    X = df.drop(columns=['Date', target])\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # Hyperparameter\n",
        "    param_grid = {\n",
        "        'num_leaves': [31, 63],\n",
        "        'max_depth': [-1, 10, 20],\n",
        "        'learning_rate': [0.1, 0.01],\n",
        "        'n_estimators': [100, 200]\n",
        "    }\n",
        "\n",
        "    # GridSearchCV\n",
        "    model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1)\n",
        "    grid_search = GridSearchCV(estimator=model,\n",
        "                               param_grid=param_grid,\n",
        "                               cv=3,\n",
        "                               scoring='neg_mean_squared_error',\n",
        "                               verbose=0,\n",
        "                               n_jobs=-1)\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    print(\"Best Parameters:\")\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "    # Prediction\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Evaluation\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n Evaluation:\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"RÂ² Score: {r2:.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    test_index = np.arange(len(y_test))\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(test_index, y_test.values, label='Actual', linewidth=2)\n",
        "    plt.plot(test_index, y_pred, label='Predicted', linewidth=2)\n",
        "    plt.title(f'{target}: Actual vs Predicted (LightGBM)')\n",
        "    plt.xlabel('Test Sample Index')\n",
        "    plt.ylabel(target)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRMQjdU2jPeZ"
      },
      "outputs": [],
      "source": [
        "lightgbm_model(df, 'Target_1day')\n",
        "lightgbm_model(df, 'Target_1week')\n",
        "lightgbm_model(df, 'Target_1month')\n",
        "lightgbm_model(df, 'Target_1year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWRDzLKMjPeZ"
      },
      "outputs": [],
      "source": [
        "lightgbm_model(df_pca, 'Target_1day')\n",
        "lightgbm_model(df_pca, 'Target_1week')\n",
        "lightgbm_model(df_pca, 'Target_1month')\n",
        "lightgbm_model(df_pca, 'Target_1year')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Model"
      ],
      "metadata": {
        "id": "OzSkKSw9HxJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBegYdknMpwu",
        "outputId": "5b550aaf-2110-44a1-d8b2-8f4236f0f097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends',\n",
            "       'Stock Splits', 'GDP (Billions USD)', 'Unemployment Rate (%)',\n",
            "       ...\n",
            "       'positive_lag14', 'positive_lag30', 'Articles_Negative_x',\n",
            "       'Articles_Neutral_x', 'Articles_positive_x', 'Articles_avg_sentiment_x',\n",
            "       'Articles_Negative_y', 'Articles_Neutral_y', 'Articles_positive_y',\n",
            "       'Articles_avg_sentiment_y'],\n",
            "      dtype='object', length=1083)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 1"
      ],
      "metadata": {
        "id": "MYdSwZ_VMM8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix version conflicts causing LightningModule error\n",
        "!pip install pytorch-lightning==1.9.4 pytorch-forecasting==0.10.1 torch==1.13.1\n",
        "!pip install sklearn numpy pandas matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "atw21Rs6Mjdi",
        "outputId": "25292052-0c8f-4368-faf8-c96981a28815"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.9.4\n",
            "  Using cached pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-forecasting==0.10.1\n",
            "  Using cached pytorch_forecasting-0.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torch==1.13.1\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (1.7.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (4.13.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.4) (0.14.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting==0.10.1) (3.10.0)\n",
            "Collecting optuna<3.0.0,>=2.3.0 (from pytorch-forecasting==0.10.1)\n",
            "  Using cached optuna-2.10.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pandas<2.0.0,>=1.3.0 (from pytorch-forecasting==0.10.1)\n",
            "  Using cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-learn<1.1,>=0.24 (from pytorch-forecasting==0.10.1)\n",
            "  Using cached scikit-learn-1.0.2.tar.gz (6.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder\n",
        "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "W7SBCejPFxmG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep essential columns from your documentation\n",
        "required_columns = [\n",
        "    'Date', 'Ticker', 'Target_1day', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
        "    'GDP (Billions USD)', 'Unemployment Rate (%)', 'positive', 'neutral', 'negative'\n",
        "] + [f\"emb_{i}\" for i in range(768)]  # From Data_Collection.ipynb\n",
        "\n",
        "# Add lagged features from Methodology.pdf\n",
        "lags = [1, 3, 5, 7, 14, 30]\n",
        "for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "    for lag in lags:\n",
        "        df[f'{col}_lag{lag}'] = df.groupby('Ticker')[col].shift(lag)\n",
        "\n",
        "# PCA for embeddings (from Methodology.pdf Section 2.2)\n",
        "embedding_cols = [f\"emb_{i}\" for i in range(768)]\n",
        "pca = PCA(n_components=17)\n",
        "df[[f\"pca_{i}\" for i in range(17)]] = pca.fit_transform(df[embedding_cols])"
      ],
      "metadata": {
        "id": "6M2eyuUxaD5Y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time index with prediction horizon awareness\n",
        "max_prediction_length = 1\n",
        "df[\"time_idx\"] = df.groupby(\"Ticker\").cumcount()\n",
        "max_time_idx = df.groupby(\"Ticker\")[\"Date\"].transform('nunique') - max_prediction_length - 1\n",
        "df = df[df[\"time_idx\"] <= max_time_idx]"
      ],
      "metadata": {
        "id": "qM44hA65Tl7t"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_cutoff = df[\"time_idx\"].max() - max_prediction_length - 1  # Time-based split\n",
        "\n",
        "training = TimeSeriesDataSet(\n",
        "    df[df.time_idx <= training_cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Target_1day\",\n",
        "    group_ids=[\"Ticker\"],\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    time_varying_known_reals=[\n",
        "        'Open', 'High', 'Low', 'Volume',\n",
        "        'GDP (Billions USD)', 'Unemployment Rate (%)'\n",
        "    ] + [f\"{col}_lag{l}\" for l in lags for col in ['Open', 'High', 'Low', 'Close', 'Volume']],\n",
        "    time_varying_unknown_reals=[\n",
        "        'Close', 'positive', 'negative', 'neutral'\n",
        "    ] + [f\"pca_{i}\" for i in range(17)],\n",
        "    max_encoder_length=30,\n",
        "    max_prediction_length=1,\n",
        "    target_normalizer=GroupNormalizer(groups=[\"Ticker\"], transformation=\"softplus\"),\n",
        ")\n",
        "\n",
        "# Proper validation set from EDA findings\n",
        "validation = TimeSeriesDataSet(\n",
        "    df[df.time_idx > training_cutoff - 30],  # Maintain encoder context\n",
        "    time_varying_known_reals=training.time_varying_known_reals,\n",
        "    time_varying_unknown_reals=training.time_varying_unknown_reals,\n",
        "    **training.get_parameters()\n",
        ")"
      ],
      "metadata": {
        "id": "SasoyAk7UmaA",
        "outputId": "669bb080-3dac-4582-9e67-96f2cf1e613b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "7 (0.12%) of Open_lag1 values were found to be NA or infinite (even after encoding). NA values are not allowed `allow_missing_timesteps` refers to missing rows, not to missing values. Possible strategies to fix the issue are (a) dropping the variable Open_lag1, (b) using `NaNLabelEncoder(add_nan=True)` for categorical variables, (c) filling missing values and/or (d) optionally adding a variable indicating filled values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-d5acdfec1e25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_prediction_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Time-based split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m training = TimeSeriesDataSet(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_idx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtraining_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"time_idx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# check that all tensors are finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m_check_tensors\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   1492\u001b[0m                         \u001b[0mcheck_for_nonfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m                     \u001b[0mcheck_for_nonfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mcheck_for_nonfinite\u001b[0;34m(tensor, names)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mna\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0;34mf\"{na} ({na / tensor.size(0):.2%}) of {name} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m\"values were found to be NA or infinite (even after encoding). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 7 (0.12%) of Open_lag1 values were found to be NA or infinite (even after encoding). NA values are not allowed `allow_missing_timesteps` refers to missing rows, not to missing values. Possible strategies to fix the issue are (a) dropping the variable Open_lag1, (b) using `NaNLabelEncoder(add_nan=True)` for categorical variables, (c) filling missing values and/or (d) optionally adding a variable indicating filled values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=2)\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n"
      ],
      "metadata": {
        "id": "3MAfbj7ILPoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training,\n",
        "    hidden_size=32,\n",
        "    attention_head_size=4,\n",
        "    dropout=0.3,\n",
        "    hidden_continuous_size=32,\n",
        "    loss=QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]),\n",
        "    learning_rate=0.03,\n",
        "    optimizer=\"ranger\",\n",
        "    output_size=7  # Must match quantile count\n",
        ")\n"
      ],
      "metadata": {
        "id": "qX16nfyKQFxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=50,\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    gradient_clip_val=0.1,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10),\n",
        "        LearningRateMonitor(),\n",
        "        ModelCheckpoint(\n",
        "            dirpath=\"checkpoints\",\n",
        "            filename=\"best-tft-{epoch}-{val_loss:.2f}\",\n",
        "            save_top_k=1,\n",
        "            monitor=\"val_loss\"\n",
        "        )\n",
        "    ],\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "hps7SYTCLSPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Critical validation before training\n",
        "print(isinstance(tft, pl.LightningModule))  # Should return True\n",
        "print(next(iter(train_dataloader))[0].keys())  # Verify feature names\n",
        "\n",
        "trainer.fit(\n",
        "    tft,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader\n",
        ")\n"
      ],
      "metadata": {
        "id": "FQnT3aX9MeZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best checkpoint\n",
        "best_model = TemporalFusionTransformer.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        ")\n",
        "\n",
        "# Quantile-based evaluation\n",
        "raw_predictions, x = best_model.predict(val_dataloader, return_x=True)\n",
        "predictions = best_model.to_prediction(raw_predictions)  # Median prediction\n",
        "actuals = torch.cat([y[0] for y in x['decoder_target']])\n",
        "\n",
        "# Calculate metrics\n",
        "mae = (actuals - predictions).abs().mean()\n",
        "print(f\"Validation MAE: {mae:.2f}\")\n",
        "\n",
        "# Feature importance analysis\n",
        "interpretation = best_model.interpret_output(raw_predictions, reduction=\"sum\")\n",
        "best_model.plot_interpretation(interpretation)\n",
        "\n",
        "# Attention visualization\n",
        "attention = best_model.predict_dataloader(val_dataloader, mode=\"attention\")\n",
        "best_model.plot_attention(attention.index[0])\n"
      ],
      "metadata": {
        "id": "O0BfRd-_TWqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2"
      ],
      "metadata": {
        "id": "3CEa1mw5MP23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import pandas as pd\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "AtDOYBw7OZrG"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preparation âž¡ï¸ Use columns from column_names.txt\n",
        "required_columns = ['Date', 'Ticker', 'Target_1day', 'Open', 'High', 'Low', 'Close',\n",
        "                   'Volume', 'GDP (Billions USD)', 'Unemployment Rate (%)',\n",
        "                   'positive', 'neutral', 'negative'] + [f\"emb_{i}\" for i in range(768)]\n",
        "\n",
        "df = df[required_columns].sort_values(by=['Ticker', 'Date'])\n",
        "\n",
        "# Create time index (critical for TFT)\n",
        "df[\"time_idx\"] = df.groupby(\"Ticker\").cumcount()\n"
      ],
      "metadata": {
        "id": "e5okdzddOZtl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define TimeSeriesDataSet âš™ï¸\n",
        "max_encoder_length = 30  # 30-day lookback window\n",
        "max_prediction_length = 1  # 1-day prediction\n",
        "\n",
        "training_cutoff = int(df[\"time_idx\"].max() * 0.8)  # 80-20 time-based split\n",
        "\n",
        "training = TimeSeriesDataSet(\n",
        "    df[df.time_idx <= training_cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Target_1day\",\n",
        "    group_ids=[\"Ticker\"],\n",
        "    static_categoricals=[\"Ticker\"],\n",
        "    time_varying_known_reals=[\n",
        "        'Open', 'High', 'Low', 'Volume',\n",
        "        'GDP (Billions USD)', 'Unemployment Rate (%)'\n",
        "    ],\n",
        "    time_varying_unknown_reals=[\n",
        "        'Close', 'positive', 'negative', 'neutral'\n",
        "    ] + [f\"emb_{i}\" for i in range(768)],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    target_normalizer=GroupNormalizer(groups=[\"Ticker\"], transformation=\"softplus\"),\n",
        ")"
      ],
      "metadata": {
        "id": "923ZDu2OOZwl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create Dataloaders ðŸ“¦\n",
        "batch_size = 64\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
        "val_dataloader = training.to_dataloader(train=False, batch_size=batch_size, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCiTdlMGOnPU",
        "outputId": "66ca7e8b-da15-44a5-89c9-b2d16ad0b959"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Configure TFT Model ðŸ¤–\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training,\n",
        "    hidden_size=32,\n",
        "    lstm_layers=2,\n",
        "    dropout=0.1,\n",
        "    output_size=1,\n",
        "    loss=QuantileLoss(),\n",
        "    learning_rate=0.03,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci1GDURjOnSI",
        "outputId": "d801cdd4-49b9-44dd-ab1a-27e1d5357cae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train Model ðŸ‹ï¸â™‚ï¸\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=50,\n",
        "    accelerator=\"auto\",  # Automatically detects GPU/TPU\n",
        "    devices=\"auto\",      # Uses all available devices\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10),\n",
        "        LearningRateMonitor()\n",
        "    ],\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCzBjPEyOZyW",
        "outputId": "dceeffd0-0689-4696-afa3-d96e2c65189d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "# Step 6: Evaluate Model\n",
        "# -------------------\n",
        "best_model_path = checkpoint_callback.best_model_path\n",
        "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "predictions = best_tft.predict(val_dataloader, return_y=True)\n",
        "mae = (predictions.output - predictions.y).abs().mean()\n",
        "print(f\"Validation MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "QalYs79hOtLd",
        "outputId": "87629201-ce6e-4c5f-c246-0180ed25e280"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'checkpoint_callback' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-7dc7b5d56e9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Step 6: Evaluate Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbest_tft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemporalFusionTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_callback' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate Model ðŸ“Š\n",
        "predictions = tft.predict(val_dataloader)\n",
        "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
        "\n",
        "# Calculate performance metrics\n",
        "mae = (actuals - predictions).abs().mean()\n",
        "print(f\"MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "id": "-1c6bZdoOwMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dat490",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}